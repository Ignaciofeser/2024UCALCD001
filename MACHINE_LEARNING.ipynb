{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgZ3LXwnoFHC3ncylMGnHX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ignaciofeser/2024UCALCD001/blob/main/MACHINE_LEARNING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo de Machine Learning en Colab con un Dataset de Kaggle\n",
        "Introducción:\n",
        "\n",
        "Este ejemplo tiene como objetivo introducirte en el mundo del Machine Learning utilizando Python y Colab. A través de un dataset sencillo de Kaggle, exploraremos los pasos básicos para entrenar y evaluar un modelo de clasificación.\n",
        "\n",
        "Ejercicio:\n",
        "\n",
        "Toma según corresponda los textos descriptivos y el código Pyton en el orden establecido en el texto, pásalos a un Notebook en Colab respetando las cédas de Texto y código según corresponda y preserva los cambios en Github. Adicionalmente verifica o visualiza el contenido del archivo Iris-Data. Comparte el link de tu trabajo en Github con el profesor vía mail (caludiopavon@uca.edu.ar)"
      ],
      "metadata": {
        "id": "XUDk_q_eWTfx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pasos:\n",
        "1. Importación de librerías y carga del dataset:\n",
        "Comenzaremos importando las librerías necesarias y cargando el dataset de Kaggle. En este caso, utilizaremos el conjunto de datos \"Iris\" que contiene información sobre las características de flores de diferentes especies."
      ],
      "metadata": {
        "id": "amLM0wBiWjSi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EVfh2_iXSS-Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Carga del dataset Iris de Kaggle\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "df = pd.read_csv(url, names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Preparación de los datos:\n",
        "El dataset debe estar preparado para el entrenamiento del modelo. Esto implica separar las características (atributos) de las etiquetas (clases) y dividir el conjunto de datos en entrenamiento y prueba."
      ],
      "metadata": {
        "id": "GwzwlBNBW-9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separación de características y etiquetas\n",
        "X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
        "y = df['species']\n",
        "# División del conjunto de datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "HJxK3DkPUP-s"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Entrenamiento del modelo:\n",
        "Seleccionamos un algoritmo de Machine Learning, en este caso utilizaremos K-Nearest Neighbors (KNN). Creamos una instancia del algoritmo y lo entrenamos con el conjunto de datos de entrenamiento."
      ],
      "metadata": {
        "id": "0MmFR0T_XeUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación del modelo KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "# Entrenamiento del modelo\n",
        "knn.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "V8FE_aZNUkPZ",
        "outputId": "fc836ec7-94cc-4262-913b-70af896b9ae8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Evaluación del modelo:\n",
        "Utilizamos el conjunto de datos de prueba para evaluar el rendimiento del modelo entrenado. Calculamos la precisión, que indica el porcentaje de predicciones correctas."
      ],
      "metadata": {
        "id": "lthZrDkvXf4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones sobre el conjunto de datos de prueba\n",
        "y_pred = knn.predict(X_test)\n",
        "# Cálculo de la precisión\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3JPBHfJUkmq",
        "outputId": "d4484050-2e8c-440e-d4d0-0600a86deb24"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "En este ejemplo, hemos realizado un proceso básico de Machine Learning:\n",
        "1. Carga y preparación de datos: El dataset se carga de una fuente externa y se prepara para el entrenamiento del modelo.\n",
        "2. Selección del algoritmo: Se selecciona un algoritmo de Machine Learning adecuado para la tarea (en este caso, clasificación).\n",
        "3. Entrenamiento del modelo: El modelo se entrena con el conjunto de datos de entrenamiento, aprendiendo a identificar patrones y relaciones entre las características y las etiquetas.\n",
        "4. Evaluación del modelo: Se utiliza el conjunto de datos de prueba para evaluar el rendimiento del modelo entrenado, calculando métricas como la precisión.\n",
        "Notas:\n",
        "Pandas y scikit-learn son dos bibliotecas de Python ampliamente utilizadas en el campo de la ciencia de datos.expand_more Cada una de ellas tiene un propósito específico y se complementan entre sí para ofrecer un conjunto completo de herramientas para el análisis y el modelado de datos.expand_more\n",
        "Pandas es una biblioteca para la manipulación y el análisis de datos tabulares.expand_more Brinda estructuras de datos eficientes y versátiles como DataFrames y Series, que permiten trabajar con grandes conjuntos de datos de forma sencilla e intuitiva. Entre sus principales funcionalidades se encuentran:\n",
        "Lectura y escritura de datos en diversos formatos: CSV, Excel, JSON, SQL, etc.expand_more\n",
        "Limpieza y preprocesamiento de datos: Eliminación de valores perdidos, tratamiento de valores atípicos, codificación de variables categóricas, etc.exclamation\n",
        "Análisis exploratorio de datos: Cálculo de estadísticas descriptivas, creación de visualizaciones, identificación de patrones y tendencias.exclamation\n",
        "Transformación y preparación de datos para el modelado: Selección de variables, escalado de características, creación de nuevas variables, etc.exclamation\n",
        "Scikit-learn, por otro lado, es una biblioteca para el aprendizaje automático y la minería de datos.expand_more Ofrece una amplia gama de algoritmos para tareas como:\n",
        "Clasificación: Predecir a qué categoría pertenece un nuevo dato.\n",
        "Regresión: Predecir un valor continuo para un nuevo dato.\n",
        "Agrupación: Identificar grupos de datos con características similares.exclamation\n",
        "Reducción de dimensionalidad: Disminuir la cantidad de variables sin perder información relevante.\n",
        "Selección de características: Identificar las variables más importantes para un modelo predictivo.\n",
        "Integración de Pandas y scikit-learn\n",
        "La combinación de Pandas y scikit-learn permite a los científicos de datos realizar un análisis completo de sus datos y construir modelos de aprendizaje automático robustos. Pandas se utiliza para preparar y preprocesar los datos, mientras que scikit-learn se utiliza para entrenar y evaluar los modelos.\n",
        "Ejemplo de uso:\n",
        "Imaginemos que un científico de datos quiere predecir el precio de las viviendas en función de sus características, como tamaño, ubicación, número de habitaciones, etc. Para ello, podría utilizar Pandas para cargar los datos de las viviendas, limpiarlos y preprocesarlos, y luego utilizar scikit-learn para entrenar un modelo de regresión que pueda predecir el precio de una nueva vivienda.\n",
        "En resumen:\n",
        "Pandas es una biblioteca esencial para la manipulación y el análisis de datos tabulares.expand_more\n",
        "Scikit-learn es una biblioteca esencial para el aprendizaje automático y la minería de datos.expand_more\n",
        "Juntas, Pandas y scikit-learn permiten a los científicos de datos realizar un análisis completo de sus datos y construir modelos de aprendizaje automático robustos.\n",
        "Recursos adicionales:\n",
        "Pandas: https://pandas.pydata.org/docs/\n",
        "Scikit-learn: https://scikit-learn.org/0.21/documentation.html\n",
        "Integración de Pandas y scikit-learn: https://stackoverflow.com/questions/52384400/getting-started-with-scikit-learn"
      ],
      "metadata": {
        "id": "nA1yXy8xXsRr"
      }
    }
  ]
}